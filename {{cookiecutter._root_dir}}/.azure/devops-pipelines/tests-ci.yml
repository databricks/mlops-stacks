# Run CI on pull requests to {{cookiecutter.default_branch}}
trigger:
  branches:
    include:
      - {{cookiecutter.default_branch}}
  paths:
    exclude:
      - databricks-config/**

jobs:
  - job: UnitTests
    displayName: 'Unit Tests'
    condition: |
      and(
        not(eq(variables['Build.Reason'], 'IndividualCI')),
        eq(variables['Build.Reason'], 'PullRequest'),
        eq(variables['System.PullRequest.TargetBranch'], 'refs/heads/{{cookiecutter.default_branch}}')
      )
    pool:
      vmImage: 'ubuntu-latest'

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - checkout: self
      persistCredentials: true
      clean: true
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

    - task: UsePythonVersion@0
      displayName: 'Use Python 3.8'
      inputs:
        versionSpec: 3.8

    - script: |
        python -m pip install --upgrade pip
        pip install -r test-requirements.txt
        pip install -r requirements.txt
      displayName: 'Install dependencies'

    - script: |
        pytest --junitxml=test-unit.xml
      displayName: 'Run unit tests with pytest'

  - job: IntegrationTests
    displayName: 'Integration Tests'
    dependsOn: UnitTests
    condition: succeeded()
    pool:
      vmImage: 'ubuntu-latest'

    steps:
    - checkout: self
      persistCredentials: true
      clean: true
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

    - task: UsePythonVersion@0
      displayName: 'Use Python 3.8'
      inputs:
        versionSpec: 3.8

    - script: |
        python -m pip install --upgrade pip
        pip install databricks-cli
      displayName: 'Install dependencies'

    - script: |
        set -e
        stagingAzureSpTenantId=$(stagingAzureSpTenantId)
        stagingAzureSpApplicationId=$(stagingAzureSpApplicationId)
        stagingAzureSpClientSecret=$(stagingAzureSpClientSecret)
        DATABRICKS_TOKEN=$(.azure/devops-pipelines/scripts/generate-aad-token.sh "$stagingAzureSpTenantId" "$stagingAzureSpApplicationId" "$stagingAzureSpClientSecret")
        echo "##vso[task.setvariable variable=DATABRICKS_TOKEN;issecret=true]${DATABRICKS_TOKEN}"
      displayName: 'Configure AAD auth'

    - script: |
        if [[ "$(Build.Reason)" == "PullRequest" ]]
        then
          pr_source_branch=$(System.PullRequest.SourceBranch)
          GIT_BRANCH=${pr_source_branch#refs/heads/}
        else
          ORIGINAL_BRANCH='$(Build.SourceBranch)'
          ROOT=refs/heads/
          GIT_BRANCH="${ORIGINAL_BRANCH/$ROOT/''}"
        fi
        databricks jobs configure --version=2.1
        databricks runs submit --wait --json \
          '{
            "run_name": "integration-test",
            "tasks": [
              {
                "task_key": "training",
                "notebook_task": {
                  "notebook_path": "notebooks/Train",
                  "base_parameters": {
                    "env": "staging",
                    "test_mode": "True"
                    }
                  },
                "new_cluster": {
                  "node_type_id": "Standard_D3_v2",
                  "spark_version": "11.2.x-cpu-ml-scala2.12",
                  "num_workers": 0,
                  "spark_conf": {
                    "spark.master": "local[*,4]",
                    "spark.databricks.cluster.profile": "singleNode"
                    },
                  "custom_tags": {
                    "ResourceClass": "SingleNode",
                    "clusterSource": "mlops-stack/0.0"
                    }
                  }
                }
              ],
            "git_source": {
              "git_url": "$(Build.Repository.Uri)",
              "git_branch": "'"$GIT_BRANCH"'",
              "git_provider": "azureDevOpsServices"
              }
          }'
      env:
        DATABRICKS_HOST: $(stagingDatabricksHost)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
      displayName: 'Trigger integration test'

    - task: PublishTestResults@2
      condition: succeededOrFailed()
      inputs:
        testResultsFormat: 'JUnit'
        testResultsFiles: '**/test-*.xml'
        failTaskOnFailedTests: true
