experiment:
  name: {% raw -%}{{ ('../databricks-config/output/prod.json' | from_json){% endraw %}["{{cookiecutter.project_name}}_experiment_name"]["value"]{% raw-%}}}{% endraw %}

# Set the registry server URI. This property is especially useful if you have a registry
# server thatâ€™s different from the tracking server.
model_registry:
  # The MLflow registered model name under which to register model versions
  # In prod, we log to the model provisioned through ML configs under databricks-config
  # See databricks-config/README.md for details
  model_name: {% raw -%}{{ ('../databricks-config/output/prod.json' | from_json){% endraw %}["{{cookiecutter.project_name}}_model_name"]["value"]{% raw %}}}{% endraw %}

# Override the default train / validation / test dataset split ratios
SPLIT_RATIOS: [0.75, 0.125, 0.125]

INGEST_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#ingest-step
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: update this field to point to the path to your model training dataset on your production Databricks workspace
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

INGEST_SCORING_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#batch-scoring
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: Specify the name/path of the input table for batch inference in your prod workspace here
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

PREDICT_OUTPUT_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#predict-step
  # Specify the output format of the batch scoring predict step
  using: table
  # TODO: Specify the name of the output table for batch inference in your prod workspace here
  location: "{{cookiecutter.project_name}}_batch_scoring"
