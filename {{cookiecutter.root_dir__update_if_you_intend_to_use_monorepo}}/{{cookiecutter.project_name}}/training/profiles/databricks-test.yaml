experiment:
  name: "{{cookiecutter.mlflow_experiment_parent_dir}}/{{cookiecutter.experiment_base_name}}-test"

# Set the registry server URI. This property is especially useful if you have a registry
# server thatâ€™s different from the tracking server.
model_registry:
  # Specifies the name of the Registered Model to use when registering a trained model to
  # the MLflow Model Registry
  model_name: "{{cookiecutter.model_name}}-test"

# Override the default train / validation / test dataset split ratios
SPLIT_RATIOS: [0.75, 0.125, 0.125]

INGEST_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#ingest-step
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: update this field to point to the path to your model training dataset on your staging Databricks workspace,
  # to be used in tests. For example, you may want to create a down-sampled version of your full production dataset
  # and specify its path here.
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

INGEST_SCORING_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#batch-scoring
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: Specify the name/path of the input table for batch inference tests here
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

PREDICT_OUTPUT_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#predict-step
  # Specify the output format of the batch scoring predict step
  using: table
  # TODO: Specify the name of the output table for batch inference in tests here
  location: "{{cookiecutter.project_name}}_batch_scoring_test"
